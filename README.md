# Computer Science Student

### Contacts
Please feel free to reach out! Find me on [LinkedIn](www.linkedin.com/in/collin-riddle-furman) or email me at mr5542015@gmail.com!

## About Me
Hello and welcome to my portfolio! My name is Collin Riddle and I'm a Computer Science major with a minor in Data Analytics at Furman University. I'm a driven student with a passion anything Computer Science related, whether that be in the classroom or out in my personal time working on projects. I am currently focusing my academics towards the data sector (ex., development and analytics) as I have developed a passion for problem solving, identifying trends, protecting data, and utilizing my intuition to find solutions to unique problems. I have strong experience in several programming languages and other necessary applications which allows me to communicate and work efficiently. I'm constantly looking for more opportunities to be involved on my campus, find leadership opportunities, and grow as a student.

## Technical Skills

**Programming Languages**  
Java (intermediate), Python (proficient), JavaScript (intermediate), React.js (beginner), MIPS Assembly 32-bit (intermediate)

**Database & Analytics**  
mySQL (intermediate), SQL Server Management Studio (intermediate), PowerBI (intermediate), Tableau (intermediate)

**Development Tools & Platforms**  
GitHub (proficient), Web Development Tools (intermediate), Virtualization Tools - VirtualBox (intermediate)

**Operating Systems & Command Line**  
Linux CLI (intermediate), Windows CLI (intermediate)

**Productivity Software**  
Microsoft Office Suite (proficient), Jira (proficient), Jira Service Management (proficient)

## Education		        		
- B.S., Computer Science | Furman University (_May 2026_)
- Minor in Data Analytics

## Work Experience
**Analytics Engineering Intern @ InvestiNet (_May 2025 - December 2025_)** 
- Developed a Python-based data application using Streamlit and Pandas to integrate multiple internal tools and engines, improving user accessibility and operational workflows.
- Designed and implemented an automated data pipeline that extracts, transforms, and loads data to ultimately generate dashboards, boosting visibility and enabling timely insights for company teams and clients.
- Fulfilled internal data requests to aid in workflow and decision-making.

**Library Assistant @ Furman University (_May 2024 - Present_)**
- Worked closely with library personnel to coordinate book acquisitions and utilizing software systems to assist library daily.
- Completed over 15 hours of comprehensive training on library information systems and academic databases, enabling the effective guidance of students in research and resource location weekly.

**Housing Staff @ Furman University (_July 2023 - August 2023_)**
- Aided housing management in the movement of supplies for several camps and conferences while fulfilling numerous work requests from residents on a weekly basis. I was able to learn excellent communcation skills, focus on details, and learn how to effectively serve people and prioritize their needs.

## Projects

### DataJourney (_Fall 2025_)
- DataJourney is an interactive exploratory interface whereusers can see the start-to-finish process of data pipelines.
- Developed during my senior seminar using a React.js framework with data pipelines created using Python and various popular plugins. 

### Geometry Fact Computer (_Spring 2024_)
- This was a Data Structures and Algorithms class project centered around the use object-oriented programming and Java's main data structures (maps, trees, linked lists, etc.) We utilized GitHub freqently for pushing and pulling our changes in an effective manner.
- More on the technical side, majority of this project was focused on creating a parser that could parse a JSON-formatted file and identify points, segments, angles, and triangles. With as many classes and working pieces as this project took, I learned how to apply interfaces, use inheritance, use generic types, and implement a fair amount of frameworks (hash maps and sets, array lists, JSON objects, etc.) 
- While spending a great deal of time refining technical skills, I also learned how to effectively communicate struggles, capitalize on successes, and generally turn the group into one cohesive unit throughout the semester.

### Restaurant Website (_Fall 2024_)
- This project, in which myself and a group of three others (Case Riddle, Jack Roberts, and Ellie Johnson) are working to create a fully functioning website. We are creating a method of searching for restaurants from in and around Greenville, South Carolina through food type, location, ratings, and so on.
- To facilitate this process, we utilized a fair bit of HTML, CSS, and JavaScript to create a basic skeleton for the Website's frontend. We utilize AJAX to allow for better transporting of data (in JSON) from our backend (Flask) to the frotend. We  used GET and POST requests, Flask templates (using Jinja syntax), and lastly configured Nginx and Gunicorn to host the website on a Furman server (with significant aid from Professor Drucker at Furman).

### Hollywoodâ€™s Hidden Numbers: A Revenue Estimation Project (_Spring 2025_)
- The following project was for my CSC-272 course, Data Mining, taught by Dr. Treu. The underlying premise of this project was to find a dataset and perform the full process of data mining in order to unconver some interesting insights.
- Our initial dataset sources from Kaggle (https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset), specifically the **movies_metadata** CSV. Our goal in this process was to see if we could reasonably predict revenue given an array of attributes.
- Much preprocessing was required during this project that warranted the need for Python scripting such that the dataset was readable in Weka (our professors choice program for creating models and performing algorithms). This Python script alongside the rest of the files used in this project can be found on my GitHub page under the name seen above.
- After performing the preprocessing, we did extensive analysis and took considerable time experimenting ultimately settling on a model created through Random Forest. The exact specifications of this project are detailed in a paper (also seen in the GitHub repository).
- In all, this project served as an incredible baseline to understanding data mining practices, experiemntation, and the overall process. This was incredibly challenging but taught myself and my group much about how this field works. In the future, I'd like to further my skills in this field, diving deeper into the algorithms and applications (like Tableau) that served as great aids in this project.

## Involvements
**Risk Manager + Standards Chair @ Pi Kappa Phi**
Led a risk management team while collaborating with the executive board and national representations, showing leadership and interpersonal skills in a 60+ member organization.
